{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the inital csv's at the start of the season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_columns = [\"name\", \"element\", \"GW\", \"bonus\", \"clean_sheets\", \"goals_conceded\", \"minutes\", \"own_goals\", \"penalties_saved\", \"saves\", \"selected\", \"transfers_balance\", \"yellow_cards\", \"value\", \"total_points\"]\n",
    "df_GK = pd.DataFrame(columns=gk_columns)\n",
    "df_GK.to_csv(\"current_season_GK.csv\", index=False)\n",
    "\n",
    "def_columns = [\"name\", \"element\", \"GW\", \"bonus\", \"assists\", \"clean_sheets\", \"goals_conceded\", \"minutes\", \"own_goals\", \"penalties_saved\", \"saves\", \"selected\", \"transfers_balance\", \"yellow_cards\", \"value\", \"total_points\"]\n",
    "df_DEF = pd.DataFrame(columns=def_columns)\n",
    "df_DEF.to_csv(\"current_season_DEF.csv\", index=False)\n",
    "\n",
    "mid_columns = [\"name\", \"element\", \"GW\", \"assists\", \"bonus\", \"goals_scored\", \"minutes\", \"own_goals\", \"saves\", \"selected\", \"transfers_balance\", \"yellow_cards\", \"value\", \"total_points\"]\n",
    "df_MID = pd.DataFrame(columns=mid_columns)\n",
    "df_MID.to_csv(\"current_season_MID.csv\", index=False)\n",
    "\n",
    "fwd_columns = [\"name\", \"element\", \"GW\", \"bonus\", \"clean_sheets\", \"goals_conceded\", \"minutes\", \"own_goals\", \"penalties_saved\", \"saves\", \"selected\", \"value\", \"transfers_balance\", \"yellow_cards\", \"total_points\"]\n",
    "df_FWD = pd.DataFrame(columns=fwd_columns)\n",
    "df_FWD.to_csv(\"current_season_FWD.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the current gameweek\n",
    "current_gw = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data for all  players\n",
    "url = \"https://fantasy.premierleague.com/api/bootstrap-static/\"\n",
    "response = requests.get(url)\n",
    "data = json.loads(response.content)\n",
    "players = data[\"elements\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block (and the next three) is iterating through a list of players, extracting information only for players who are defenders (indicated by player \"element_type being \"DEF\").\n",
    "\n",
    "1. Iterating Through Players: The for loop iterates through each player in the players list.\n",
    "\n",
    "2. Filtering Defenders: Inside the loop, the if statement checks if the player's element type is \"DEF\", meaning the player is a defender.\n",
    "\n",
    "3. Extracting Player Data: For each defender, the code extracts various statistics such as name, ID, game week (GW), bonus, assists, clean sheets, goals conceded, minutes played, own goals, penalties saved, saves, selection status, transfer balance, yellow cards, value, and total points. These statistics are stored in a dictionary and appended to the DataFrame df.\n",
    "\n",
    "4. Saving the DataFrame: After looping through all the players and extracting the necessary information, the DataFrame df is saved to a CSV file named \"gw-data_DEF.csv\". This file contains all the extracted information for defenders and can be used for further analysis.\n",
    "\n",
    "This code block is useful for gathering and saving specific data related to defenders in a soccer game or league. By focusing on defenders, it allows for targeted analysis of the defensive aspect of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to all_players_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Get the data for all players\n",
    "url = \"https://fantasy.premierleague.com/api/bootstrap-static/\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Convert the \"elements\" list to a DataFrame\n",
    "df = pd.DataFrame(data[\"elements\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = \"all_players_data.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f\"Data saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to gw-data_GK.csv\n",
      "Data saved to gw-data_DEF.csv\n",
      "Data saved to gw-data_MID.csv\n",
      "Data saved to gw-data_FWD.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV containing all players' data\n",
    "df_all_players = pd.read_csv(\"all_players_data.csv\")\n",
    "\n",
    "# Filter the dataframe to get only goalkeepers\n",
    "goalkeepers = df_all_players[df_all_players[\"element_type\"] == 1]\n",
    "\n",
    "# Extract and format the required columns for goalkeepers\n",
    "df_goalkeepers = pd.DataFrame({\n",
    "    \"name\": goalkeepers[\"first_name\"] + ' ' + goalkeepers[\"second_name\"],\n",
    "    \"element\": goalkeepers[\"id\"],\n",
    "    \"GW\": current_gw,  \n",
    "    \"bonus\": goalkeepers[\"bonus\"],\n",
    "    \"clean_sheets\": goalkeepers[\"clean_sheets\"],\n",
    "    \"goals_conceded\": goalkeepers[\"goals_conceded\"],\n",
    "    \"minutes\": goalkeepers[\"minutes\"],\n",
    "    \"own_goals\": goalkeepers[\"own_goals\"],\n",
    "    \"penalties_saved\": goalkeepers[\"penalties_saved\"],\n",
    "    \"saves\": goalkeepers[\"saves\"],\n",
    "    \"selected\": goalkeepers[\"selected_by_percent\"],\n",
    "    \"transfers_balance\": goalkeepers[\"transfers_in\"] - goalkeepers[\"transfers_out\"],  # Derived transfers_balance\n",
    "    \"yellow_cards\": goalkeepers[\"yellow_cards\"],\n",
    "    \"value\": goalkeepers[\"now_cost\"] / 10,  # Divided by 10 to get the actual value\n",
    "    \"total_points\": goalkeepers[\"total_points\"]\n",
    "})\n",
    "\n",
    "# Save the extracted data to a new CSV\n",
    "csv_goalkeepers_filename = \"gw-data_GK.csv\"\n",
    "df_goalkeepers.to_csv(csv_goalkeepers_filename, index=False)\n",
    "print(f\"Data saved to {csv_goalkeepers_filename}\")\n",
    "\n",
    "# Read the CSV containing all players' data\n",
    "df_all_players = pd.read_csv(\"all_players_data.csv\")\n",
    "\n",
    "# Filter the dataframe to get only defenders\n",
    "defenders = df_all_players[df_all_players[\"element_type\"] == 2]\n",
    "\n",
    "# Extract and format the required columns for defenders\n",
    "df_defenders = pd.DataFrame({\n",
    "    \"name\": defenders[\"first_name\"] + ' ' + defenders[\"second_name\"],\n",
    "    \"element\": defenders[\"id\"],\n",
    "    \"GW\": current_gw,  \n",
    "    \"bonus\": defenders[\"bonus\"],\n",
    "    \"assists\": defenders[\"assists\"],\n",
    "    \"clean_sheets\": defenders[\"clean_sheets\"],\n",
    "    \"goals_conceded\": defenders[\"goals_conceded\"],\n",
    "    \"minutes\": defenders[\"minutes\"],\n",
    "    \"own_goals\": defenders[\"own_goals\"],\n",
    "    \"penalties_saved\": defenders[\"penalties_saved\"],\n",
    "    \"saves\": defenders[\"saves\"],\n",
    "    \"selected\": defenders[\"selected_by_percent\"],\n",
    "    \"transfers_balance\": defenders[\"transfers_in\"] - defenders[\"transfers_out\"],  # Derived transfers_balance\n",
    "    \"yellow_cards\": defenders[\"yellow_cards\"],\n",
    "    \"value\": defenders[\"now_cost\"] / 10,  # Divided by 10 to get the actual value\n",
    "    \"total_points\": defenders[\"total_points\"]\n",
    "})\n",
    "\n",
    "# Save the extracted data to a new CSV\n",
    "csv_defenders_filename = \"gw-data_DEF.csv\"\n",
    "df_defenders.to_csv(csv_defenders_filename, index=False)\n",
    "print(f\"Data saved to {csv_defenders_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "# Filter the dataframe to get only midfielders\n",
    "midfielders = df_all_players[df_all_players[\"element_type\"] == 3]\n",
    "\n",
    "\n",
    "\n",
    "# Extract and format the required columns for midfielders\n",
    "df_mid = pd.DataFrame({\n",
    "    \"name\": midfielders[\"first_name\"] + ' ' + midfielders[\"second_name\"],\n",
    "    \"element\": midfielders[\"id\"],\n",
    "    \"GW\": current_gw,\n",
    "    \"assists\": midfielders[\"assists\"],\n",
    "    \"bonus\": midfielders[\"bonus\"],\n",
    "    \"goals_scored\": midfielders[\"goals_scored\"],\n",
    "    \"minutes\": midfielders[\"minutes\"],\n",
    "    \"own_goals\": midfielders[\"own_goals\"],\n",
    "    \"saves\": midfielders[\"saves\"],\n",
    "    \"selected\": midfielders[\"selected_by_percent\"],\n",
    "    \"transfers_balance\": midfielders[\"transfers_in\"] - midfielders[\"transfers_out\"],  # Derived transfers_balance\n",
    "    \"yellow_cards\": midfielders[\"yellow_cards\"],\n",
    "    \"value\": midfielders[\"now_cost\"]/10,  # Divided by 10 to get the actual value\n",
    "    \"total_points\": midfielders[\"total_points\"]\n",
    "})\n",
    "\n",
    "# Save the extracted data to a new CSV\n",
    "csv_mid_filename = \"gw-data_MID.csv\"\n",
    "df_mid.to_csv(csv_mid_filename, index=False)\n",
    "print(f\"Data saved to {csv_mid_filename}\")\n",
    "\n",
    "\n",
    "# Filter the dataframe to get only forwards\n",
    "forwards = df_all_players[df_all_players[\"element_type\"] == 4]\n",
    "\n",
    "\n",
    "# Extract and format the required columns for forwards\n",
    "df_fwd = pd.DataFrame({\n",
    "    \"name\": forwards[\"first_name\"] + ' ' + forwards[\"second_name\"],\n",
    "    \"element\": forwards[\"id\"],\n",
    "    \"GW\": current_gw,\n",
    "    \"bonus\": forwards[\"bonus\"],\n",
    "    \"clean_sheets\": forwards[\"clean_sheets\"],\n",
    "    \"goals_conceded\": forwards[\"goals_conceded\"],\n",
    "    \"minutes\": forwards[\"minutes\"],\n",
    "    \"own_goals\": forwards[\"own_goals\"],\n",
    "    \"penalties_saved\": forwards[\"penalties_saved\"],\n",
    "    \"saves\": forwards[\"saves\"],\n",
    "    \"selected\": forwards[\"selected_by_percent\"],\n",
    "    \"value\": forwards[\"now_cost\"]/10,  # Divided by 10 to get the actual value\n",
    "    \"transfers_balance\": forwards[\"transfers_in\"] - forwards[\"transfers_out\"],  # Derived transfers_balance\n",
    "    \"yellow_cards\": forwards[\"yellow_cards\"],\n",
    "    \"total_points\": forwards[\"total_points\"]\n",
    "})\n",
    "\n",
    "\n",
    "# Save the extracted data to a new CSV\n",
    "csv_fwd_filename = \"gw-data_FWD.csv\"\n",
    "df_fwd.to_csv(csv_fwd_filename, index=False)\n",
    "print(f\"Data saved to {csv_fwd_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the most recent GW data, we need to combine this to the current_season csvs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block is responsible for reading, merging, sorting, and updating the data related to players' performance in a soccer game or league. It's organized into several steps:\n",
    "\n",
    "1. Reading the Data: The code begins by reading data from CSV files named \"gw-data_*.csv\" and \"current_season_*.csv\", where * represents different player positions (Goalkeeper, Defender, Midfielder, Forward). The data is loaded into DataFrames for each position, such as df_GK, df_DEF, df_MID, and df_FWD.\n",
    "\n",
    "2. Merging the DataFrames: The code then merges the data from the \"game week\" (gw-data_*.csv) files with the data from the \"current season\" (current_season_*.csv) files for each player position. The merge is performed using an outer join on the columns \"name\", \"element\", and \"GW\", resulting in new merged DataFrames like df_merged_GK, df_merged_DEF, etc.\n",
    "\n",
    "3. Sorting the Merged Data: The merged DataFrames are sorted by the player's name and game week (GW), ensuring the data is organized in a logical order.\n",
    "\n",
    "4. Applying Mean Reversion: If the current game week (current_gw) is less than or equal to 3, the code sets a new column 'mean_reversion' to 0 for each merged DataFrame. This might be used for statistical analysis or modeling, though without further context, the exact purpose of this operation is unclear.\n",
    "\n",
    "Saving the Merged Data: Finally, the code saves the updated and merged DataFrames back to CSV files named \"current_season_*.csv\", overwriting theoriginal \"current season\" files. The index=False parameter ensures that the DataFrame index is not written to the CSV file.\n",
    "\n",
    "This code segment is a crucial part of the data preprocessing and management process, providing a well-organized and consolidated view of player statistics for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['penalties_saved', 'goals_conceded', 'clean_sheets'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-291d5c9a51ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf_DEF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_DEF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_current_season_DEF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf_MID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_MID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_current_season_MID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf_FWD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_FWD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_current_season_FWD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Append the dataframes for each position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['penalties_saved', 'goals_conceded', 'clean_sheets'] not in index\""
     ]
    }
   ],
   "source": [
    "# Read the data from the \"gw-data_*.csv\" files\n",
    "df_GK = pd.read_csv(\"gw-data_GK.csv\")\n",
    "df_DEF = pd.read_csv(\"gw-data_DEF.csv\")\n",
    "df_MID = pd.read_csv(\"gw-data_MID.csv\")\n",
    "df_FWD = pd.read_csv(\"gw-data_FWD.csv\")\n",
    "\n",
    "# Read the data from the \"current_season_*.csv\" files\n",
    "df_current_season_GK = pd.read_csv(\"current_season_GK.csv\")\n",
    "df_current_season_DEF = pd.read_csv(\"current_season_DEF.csv\")\n",
    "df_current_season_MID = pd.read_csv(\"current_season_MID.csv\")\n",
    "df_current_season_FWD = pd.read_csv(\"current_season_FWD.csv\")\n",
    "\n",
    "\n",
    "# Ensure columns are in the same order before concatenating\n",
    "df_GK = df_GK[df_current_season_GK.columns]\n",
    "df_DEF = df_DEF[df_current_season_DEF.columns]\n",
    "df_MID = df_MID[df_current_season_MID.columns]\n",
    "df_FWD = df_FWD[df_current_season_FWD.columns]\n",
    "\n",
    "# Append the dataframes for each position\n",
    "df_merged_GK = pd.concat([df_current_season_GK, df_GK], ignore_index=True)\n",
    "df_merged_DEF = pd.concat([df_current_season_DEF, df_DEF], ignore_index=True)\n",
    "df_merged_MID = pd.concat([df_current_season_MID, df_MID], ignore_index=True)\n",
    "df_merged_FWD = pd.concat([df_current_season_FWD, df_FWD], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Append the dataframes for each position\n",
    "df_merged_GK = pd.concat([df_current_season_GK, df_GK], ignore_index=True)\n",
    "df_merged_DEF = pd.concat([df_current_season_DEF, df_DEF], ignore_index=True)\n",
    "df_merged_MID = pd.concat([df_current_season_MID, df_MID], ignore_index=True)\n",
    "df_merged_FWD = pd.concat([df_current_season_FWD, df_FWD], ignore_index=True)\n",
    "\n",
    "# Drop duplicate columns (ones with suffixes)\n",
    "cols_to_keep_GK = [col for col in df_merged_GK.columns if not col.endswith(\".1\") and not col.endswith(\".2\")]\n",
    "cols_to_keep_DEF = [col for col in df_merged_DEF.columns if not col.endswith(\".1\") and not col.endswith(\".2\")]\n",
    "cols_to_keep_MID = [col for col in df_merged_MID.columns if not col.endswith(\".1\") and not col.endswith(\".2\")]\n",
    "cols_to_keep_FWD = [col for col in df_merged_FWD.columns if not col.endswith(\".1\") and not col.endswith(\".2\")]\n",
    "\n",
    "df_merged_GK = df_merged_GK[cols_to_keep_GK]\n",
    "df_merged_DEF = df_merged_DEF[cols_to_keep_DEF]\n",
    "df_merged_MID = df_merged_MID[cols_to_keep_MID]\n",
    "df_merged_FWD = df_merged_FWD[cols_to_keep_FWD]\n",
    "\n",
    "# Sort the merged dataframes by name and then GW\n",
    "df_merged_GK = df_merged_GK.sort_values([\"name\", \"GW\"])\n",
    "df_merged_DEF = df_merged_DEF.sort_values([\"name\", \"GW\"])\n",
    "df_merged_MID = df_merged_MID.sort_values([\"name\", \"GW\"])\n",
    "df_merged_FWD = df_merged_FWD.sort_values([\"name\", \"GW\"])\n",
    "\n",
    "if current_gw <= 3:\n",
    "    df_merged_GK['mean_reversion'] = 0\n",
    "    df_merged_DEF['mean_reversion'] = 0\n",
    "    df_merged_MID['mean_reversion'] = 0\n",
    "    df_merged_FWD['mean_reversion'] = 0\n",
    "\n",
    "# Save the merged dataframes to the \"current_season_*.csv\" files\n",
    "df_merged_GK.to_csv(\"current_season_GK.csv\", index=False)\n",
    "df_merged_DEF.to_csv(\"current_season_DEF.csv\", index=False)\n",
    "df_merged_MID.to_csv(\"current_season_MID.csv\", index=False)\n",
    "df_merged_FWD.to_csv(\"current_season_FWD.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in df_current_season_GK:\", df_current_season_GK.columns)\n",
    "print(\"Columns in df_GK:\", df_GK.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merged_GK.columns)\n",
    "print(df_merged_DEF.columns)\n",
    "print(df_merged_MID.columns)\n",
    "print(df_merged_FWD.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have consolidated the current season's data into master CSV files, our next task is to calculate the mean reversion statistic. This statistic is not provided directly by the API, so we must compute it ourselves.\n",
    "\n",
    "Mean reversion is a method of analyzing how a player's performance trends toward an average level over time. In our context, we are focusing on a three-week mean reversion. For the first three weeks, there is not enough data to calculate this statistic, so we will set the mean reversion value to 0 for these initial weeks.\n",
    "\n",
    "With the mean reversion calculation complete, we will integrate this new statistic into the master files for each player position (Goalkeepers, Defenders, Midfielders, Forwards). This will provide us with a comprehensive dataset that includes both historical data and the newly calculated mean reversion, laying the groundwork for in-depth analysis and insights into player performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code segment focuses on calculating the mean reversion for each player's total points and updating the data accordingly. The mean reversion is a statistical measure that might be used to analyze trends and patterns in the players' performance. Here's a detailed breakdown of the steps:\n",
    "\n",
    "1. Defining the Mean Reversion Function:\n",
    "\n",
    "- calculate_mean_reversion(series): This function calculates the mean reversion for a given series of data (e.g., total points for a player over different game weeks).\n",
    "- cumulative_average: Computes the cumulative average of the series up to the current week.\n",
    "- rolling_average: Calculates the rolling average of the previous three weeks.\n",
    "- mean_reversion: Subtracts the rolling average from the cumulative average to calculate the mean reversion.\n",
    "- The first three weeks are replaced with 0, as there is not enough data to calculate the rolling average for those weeks.\n",
    "\n",
    "2. Calculating Mean Reversion for Each Position:\n",
    "\n",
    "- The code applies the calculate_mean_reversion function to the 'total_points' column of each merged DataFrame (df_merged_GK, df_merged_DEF, etc.) grouped by player name. This calculates the mean reversion for each player and updates the 'mean_reversion' column in the respective DataFrames.\n",
    "\n",
    "3. Saving the Updated Data:\n",
    "\n",
    "- The updated DataFrames, now including the mean reversion calculations, are saved back to the \"current_season_*.csv\" files for each player position. The index=False parameter ensures that the DataFrame index is not written to the CSV file.\n",
    "\n",
    "The mean reversion calculation might be used in various analytical contexts, such as understanding how players' performances revert to their average level over time or identifying anomalies and trends. This code block serves as a crucial preprocessing step for such analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the mean reversion\n",
    "def calculate_mean_reversion(series):\n",
    "    # Calculate the cumulative average up to the current week\n",
    "    cumulative_average = series.expanding().mean()\n",
    "    # Calculate the rolling average of the previous three weeks\n",
    "    rolling_average = series.rolling(window=3).mean().shift(1)\n",
    "    # Subtract the rolling average from the cumulative average\n",
    "    mean_reversion = cumulative_average - rolling_average\n",
    "    # For the first three weeks, replace the NaNs with 0\n",
    "    mean_reversion[:3] = 0\n",
    "    return mean_reversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean reversion for each player\n",
    "df_merged_GK['mean_reversion'] = df_merged_GK.groupby('name')['total_points'].transform(calculate_mean_reversion)\n",
    "df_merged_DEF['mean_reversion'] = df_merged_DEF.groupby('name')['total_points'].transform(calculate_mean_reversion)\n",
    "df_merged_MID['mean_reversion'] = df_merged_MID.groupby('name')['total_points'].transform(calculate_mean_reversion)\n",
    "df_merged_FWD['mean_reversion'] = df_merged_FWD.groupby('name')['total_points'].transform(calculate_mean_reversion)\n",
    "\n",
    "# Check the first few rows to confirm the changes\n",
    "df_merged_GK.to_csv(\"current_season_GK.csv\", index=False)\n",
    "df_merged_DEF.to_csv(\"current_season_DEF.csv\", index=False)\n",
    "df_merged_MID.to_csv(\"current_season_MID.csv\", index=False)\n",
    "df_merged_FWD.to_csv(\"current_season_FWD.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [df_merged_GK, df_merged_DEF, df_merged_MID, df_merged_FWD]\n",
    "file_names = [\"current_season_GK.csv\", \"current_season_DEF.csv\", \"current_season_MID.csv\", \"current_season_FWD.csv\"]\n",
    "\n",
    "for df, file_name in zip(dataframes, file_names):\n",
    "    for col in df.columns:\n",
    "        if col.endswith('_x'):\n",
    "            df.rename(columns={col: col.rstrip('_x')}, inplace=True)\n",
    "        elif col.endswith('_y'):\n",
    "            df.rename(columns={col: col.rstrip('_y')}, inplace=True)\n",
    "        elif col.endswith('.1'):\n",
    "            df.rename(columns={col: col.rstrip('.1')}, inplace=True)\n",
    "    df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code segment is focused on extracting the data from the previous game week (GW) for each player position (Goalkeeper, Defender, Midfielder, Forward) and saving it to individual CSV files. This data will be used to feed into a predictive model that is trained on everything prior to the previous GW. Here's a step-by-step breakdown:\n",
    "\n",
    "1. Reading the Last Row: For each player position, the code reads the current season's CSV file (e.g., \"current_season_GK.csv\") and extracts the last row using the tail(1) method. This last row contains the data for the previous GW, as the files are organized chronologically.\n",
    "\n",
    "2. Saving to Individual Files: The extracted data for the previous GW is then saved to separate CSV files (\"GK_data.csv\", \"DEF_data.csv\", \"MID_data.csv\", \"FWD_data.csv\"), one for each player position. The index=False parameter ensures that the DataFrame index is not written to the CSV file.\n",
    "\n",
    "3. Usage in Prediction Model: The files \"GK_data.csv\", \"DEF_data.csv\", \"MID_data.csv\", \"FWD_data.csv\" contain the relevant data that the predictive model will use to make its predictions. By focusing on the previous GW's data, the model can make inferences based on the most recent performance trends.\n",
    "\n",
    "This step is essential in preparing the input for the predictive model, ensuring that it operates on the most relevant and timely data to generate accurate forecasts for player performance in the upcoming GW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_row_GK = pd.read_csv(\"current_season_GK.csv\").tail(1)\n",
    "last_row_DEF = pd.read_csv(\"current_season_DEF.csv\").tail(1)\n",
    "last_row_MID = pd.read_csv(\"current_season_MID.csv\").tail(1)\n",
    "last_row_FWD = pd.read_csv(\"current_season_FWD.csv\").tail(1)\n",
    "\n",
    "\n",
    "last_row_GK.to_csv(\"GK_data.csv\", index=False)\n",
    "last_row_DEF.to_csv(\"DEF_data.csv\", index=False)\n",
    "last_row_MID.to_csv(\"MID_data.csv\", index=False)\n",
    "last_row_FWD.to_csv(\"FWD_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this after the model has made its predictions using the POS_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block below we are adding the previous GW to the entire data set to train the model in the next GW. \n",
    "\n",
    "For example, before GW2, the model is trained on all data, **excluding GW1**. GW1 is used for the model to make the prediction. \n",
    "\n",
    "Before GW3, GW1 is added using the code block below and that is used to train the model, then GW2 is used for the model to make the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the last row from each \"current_season_*.csv\" file\n",
    "last_row_GK = pd.read_csv(\"current_season_GK.csv\").tail(1)\n",
    "last_row_DEF = pd.read_csv(\"current_season_DEF.csv\").tail(1)\n",
    "last_row_MID = pd.read_csv(\"current_season_MID.csv\").tail(1)\n",
    "last_row_FWD = pd.read_csv(\"current_season_FWD.csv\").tail(1)\n",
    "\n",
    "# Read the master CSV files and concatenate the last row at the top\n",
    "def append_last_row_to_master(last_row, master_file):\n",
    "    master_data = pd.read_csv(master_file)\n",
    "    updated_master_data = pd.concat([last_row, master_data], ignore_index=True)\n",
    "    updated_master_data.to_csv(master_file, index=False)\n",
    "\n",
    "# Update the master CSV files with the latest data\n",
    "append_last_row_to_master(last_row_GK, \"GK_master.csv\")\n",
    "append_last_row_to_master(last_row_DEF, \"DEF_master.csv\")\n",
    "append_last_row_to_master(last_row_MID, \"MID_master.csv\")\n",
    "append_last_row_to_master(last_row_FWD, \"FWD_master.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should now be ready to put through the NN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
